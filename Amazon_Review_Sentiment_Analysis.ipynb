{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Python Settings<div class=\"tocSkip\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working on a local system.\n",
      "Files will be searched relative to \"..\".\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    GIT_ROOT = 'https://github.com/blueprints-for-text-analytics-python/blueprints-text/raw/master'\n",
    "    os.system(f'wget {GIT_ROOT}/ch11/setup.py')\n",
    "\n",
    "%run -i setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     /home/setareh/nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path to import blueprints packages\n",
    "#sys.path.append(BASE_DIR + '/packages')\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "nltk.download('opinion_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing the Amazon Customer Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163807</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>A2A8GHFXUG1B28</td>\n",
       "      <td>B0045Z4JAI</td>\n",
       "      <td>Good Decaf... it has a good flavour for a deca...</td>\n",
       "      <td>Nice!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195640</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>A1VU337W6PKAR3</td>\n",
       "      <td>B00K0TIC56</td>\n",
       "      <td>I could not ask for a better system for my sma...</td>\n",
       "      <td>I could not ask for a better system for my sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167820</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>A1Z5TT1BBSDLRM</td>\n",
       "      <td>B0012ORBT6</td>\n",
       "      <td>good product at a good price and saves a trip ...</td>\n",
       "      <td>Four Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104268</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>A4PRXX2G8900X</td>\n",
       "      <td>B005SPI45U</td>\n",
       "      <td>I like the principle of a raw chip - something...</td>\n",
       "      <td>No better alternatives but still tastes bad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51961</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>AYETYLNYDIS2S</td>\n",
       "      <td>B00D1HLUP8</td>\n",
       "      <td>Fake China knockoff, you get what you pay for.</td>\n",
       "      <td>Definitely not OEM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall  verified      reviewerID        asin   \n",
       "163807        5     False  A2A8GHFXUG1B28  B0045Z4JAI  \\\n",
       "195640        5      True  A1VU337W6PKAR3  B00K0TIC56   \n",
       "167820        4      True  A1Z5TT1BBSDLRM  B0012ORBT6   \n",
       "104268        1     False   A4PRXX2G8900X  B005SPI45U   \n",
       "51961         1      True   AYETYLNYDIS2S  B00D1HLUP8   \n",
       "\n",
       "                                                     text   \n",
       "163807  Good Decaf... it has a good flavour for a deca...  \\\n",
       "195640  I could not ask for a better system for my sma...   \n",
       "167820  good product at a good price and saves a trip ...   \n",
       "104268  I like the principle of a raw chip - something...   \n",
       "51961      Fake China knockoff, you get what you pay for.   \n",
       "\n",
       "                                                  summary  \n",
       "163807                                              Nice!  \n",
       "195640  I could not ask for a better system for my sma...  \n",
       "167820                                         Four Stars  \n",
       "104268       No better alternatives but still tastes bad.  \n",
       "51961                                  Definitely not OEM  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file = \"./reviews_5_balanced.json.gz\"\n",
    "df = pd.read_json(file, lines=True)\n",
    "df = df.drop(columns=['reviewTime','unixReviewTime']) ###\n",
    "df = df.rename(columns={'reviewText': 'text'}) ###\n",
    "df.sample(5, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overall**\n",
    "\n",
    "* This is the final rating provided by the reviewer to the product. Ranges from 1 (lowest) to 5 (highest).\n",
    "\n",
    "**Verified**\n",
    "\n",
    "* This indicates whether the product purchase has been verified by Amazon.\n",
    "\n",
    "**ReviewerID**\n",
    "\n",
    "* This is the unique identifier allocated by Amazon to each reviewer.\n",
    "\n",
    "**ASIN**\n",
    "\n",
    "* This is a unique product code that Amazon uses to identify the product.\n",
    "\n",
    "**Text**\n",
    "\n",
    "* The actual text in the review provided by the user.\n",
    "\n",
    "**Summary**\n",
    "\n",
    "* This is the headline or summary of the review that the user provided.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained Language Models using deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning and Transfer Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an optional step to reduce the size of the data by sampling only 40% of the observations\n",
    "\n",
    "df = df.sample(frac=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212388</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>A18Q3R829Q9MFS</td>\n",
       "      <td>B00UT2OFV4</td>\n",
       "      <td>great product</td>\n",
       "      <td>Five Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58948</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>A23L2ZVK7D6LET</td>\n",
       "      <td>B00KHEJ8B6</td>\n",
       "      <td>Honestly it look really nice but I'm really ma...</td>\n",
       "      <td>Honestly it look really nice but I'm really ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253525</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>A29P7WJ9GR4L05</td>\n",
       "      <td>B000H25VVE</td>\n",
       "      <td>I LOVE IT</td>\n",
       "      <td>Five Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113127</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>A38MQ3RH7071SC</td>\n",
       "      <td>B001C8CI54</td>\n",
       "      <td>wrong size</td>\n",
       "      <td>One Star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105563</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>AKKQGGIXS7JBG</td>\n",
       "      <td>B00LY3TBKW</td>\n",
       "      <td>more than half were broken</td>\n",
       "      <td>more than half were broken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall  verified      reviewerID        asin   \n",
       "212388        5      True  A18Q3R829Q9MFS  B00UT2OFV4  \\\n",
       "58948         2      True  A23L2ZVK7D6LET  B00KHEJ8B6   \n",
       "253525        5      True  A29P7WJ9GR4L05  B000H25VVE   \n",
       "113127        1      True  A38MQ3RH7071SC  B001C8CI54   \n",
       "105563        1      True   AKKQGGIXS7JBG  B00LY3TBKW   \n",
       "\n",
       "                                                     text   \n",
       "212388                                      great product  \\\n",
       "58948   Honestly it look really nice but I'm really ma...   \n",
       "253525                                          I LOVE IT   \n",
       "113127                                         wrong size   \n",
       "105563                         more than half were broken   \n",
       "\n",
       "                                                  summary  \n",
       "212388                                         Five Stars  \n",
       "58948   Honestly it look really nice but I'm really ma...  \n",
       "253525                                         Five Stars  \n",
       "113127                                           One Star  \n",
       "105563                         more than half were broken  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verified</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14077</th>\n",
       "      <td>True</td>\n",
       "      <td>This is too thin for bed rail.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47921</th>\n",
       "      <td>True</td>\n",
       "      <td>it was ok, low cost, but after awhile using it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184567</th>\n",
       "      <td>True</td>\n",
       "      <td>Works as advertised</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        verified                                               text  sentiment\n",
       "14077       True                     This is too thin for bed rail.          0\n",
       "47921       True  it was ok, low cost, but after awhile using it...          0\n",
       "184567      True                                Works as advertised          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assigning a new [1,0] target class label based on the product rating\n",
    "df['sentiment'] = 0\n",
    "df.loc[df['overall'] > 3, 'sentiment'] = 1\n",
    "df.loc[df['overall'] < 3, 'sentiment'] = 0\n",
    "\n",
    "# Removing unecessary columns to keep a simple dataframe \n",
    "df.drop(columns=[\n",
    "    'overall', 'reviewerID', 'summary', \"asin\"],\n",
    "        inplace=True)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading models and tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers library by Hugging Face is used  because of its easy-to-use functionality and wide support for multiple pretrained models.\n",
    "\n",
    "*  Using this library, we can easily choose between different pretrained models by just changing a parameter value. The benchmark models such as BERT and GPT-2 are implement and available using this library.\n",
    "\n",
    "* We import three classes:  \n",
    "    * **config class** used to store important model parameters\n",
    "    * **the tokenizer** to tokenize and prepare the text for model training\n",
    "    * **model class** which defines the model architecture and weights. \n",
    "    \n",
    "    \n",
    "* The smallest BERT model, bert-base-uncased, which is 12 layers deep and contains 110 million parameters is used in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "config = BertConfig.from_pretrained('bert-base-uncased', finetuning_task='binary')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*  The *tokenize* function from tokenizer class splits the sentence to tokens, pads the sentence to a fixed length sequence and output the embedding representation. \n",
    "\n",
    "* An attention mask is added to differentiate those positions where we have actual words from those that\n",
    "contain padding characters. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the sentence I want embeddings for.\n",
      "['[CLS]', 'here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "[101, 2182, 2003, 1996, 6251, 1045, 2215, 7861, 8270, 4667, 2015, 2005, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings; ###\n",
    "warnings.filterwarnings('ignore'); ###\n",
    "\n",
    "def get_tokens(text, tokenizer, max_seq_length, add_special_tokens=True):\n",
    "  input_ids = tokenizer.encode(text, \n",
    "                               add_special_tokens=add_special_tokens, \n",
    "                               max_length=max_seq_length,\n",
    "                               pad_to_max_length=True,\n",
    "                              truncation=True)\n",
    "  attention_mask = [int(id > 0) for id in input_ids]\n",
    "  assert len(input_ids) == max_seq_length\n",
    "  assert len(attention_mask) == max_seq_length\n",
    "  return (input_ids, attention_mask)\n",
    "\n",
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "input_ids, attention_mask = get_tokens(text, \n",
    "                                       tokenizer, \n",
    "                                       max_seq_length=30, \n",
    "                                       add_special_tokens = True)\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "print (text)\n",
    "print (input_tokens)\n",
    "print (input_ids)\n",
    "print (attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [CLS] token, which stands for classification, which is one of the pretraining tasks of the BERT model. This token is used to identify the start of a sentence and stores the aggregated representation of the entire sentence.\n",
    "\n",
    "###  The ## is used to identify tokens that are subwords, which is a special characteristic of the BERT model. It is used to distinct between root words, prefixes, and suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df['text'],\n",
    "                                                    df['sentiment'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df['sentiment'])\n",
    "X_train_tokens = X_train.apply(get_tokens, args=(tokenizer, 50))\n",
    "X_test_tokens = X_test.apply(get_tokens, args=(tokenizer, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([94156, 50])\n",
      "torch.Size([94156, 50])\n",
      "torch.Size([94156])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "input_ids_train = torch.tensor(\n",
    "    [features[0] for features in X_train_tokens.values], dtype=torch.long)\n",
    "input_mask_train = torch.tensor(\n",
    "    [features[1] for features in X_train_tokens.values], dtype=torch.long)\n",
    "label_ids_train = torch.tensor(Y_train.values, dtype=torch.long)\n",
    "\n",
    "print (input_ids_train.shape)\n",
    "print (input_mask_train.shape)\n",
    "print (label_ids_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The token tensor contains a mapping to the BERT vocabulary. The number 101 indicates the start, and 102 indicates the end of the review sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 101, 6581, 3737,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_train[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine these tensors into a TensorDataset, which is the basic data structure used to load all observations during model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(input_ids_train,input_mask_train,label_ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_test = torch.tensor([features[0] for features in X_test_tokens.values], \n",
    "                              dtype=torch.long)\n",
    "input_mask_test = torch.tensor([features[1] for features in X_test_tokens.values], \n",
    "                               dtype=torch.long)\n",
    "label_ids_test = torch.tensor(Y_test.values, \n",
    "                              dtype=torch.long)\n",
    "test_dataset = TensorDataset(input_ids_test, input_mask_test, label_ids_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples =  94156\n",
      "Num Epochs =  2\n",
      "Total train batch size  =  64\n",
      "Total optimization steps =  736\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "train_batch_size = 64\n",
    "num_train_epochs = 2\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              sampler=train_sampler, \n",
    "                              batch_size=train_batch_size)\n",
    "t_total = len(train_dataloader) // num_train_epochs\n",
    "\n",
    "print (\"Num examples = \", len(train_dataset))\n",
    "print (\"Num Epochs = \", num_train_epochs)\n",
    "print (\"Total train batch size  = \", train_batch_size)\n",
    "print (\"Total optimization steps = \", t_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These parameters are used based on the parameters in the BERT paper and recommendations in the Transformers library,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_optimizer as optim\n",
    "\n",
    "from transformers import AdamW , get_linear_schedule_with_warmup\n",
    "\n",
    "learning_rate = 1e-4\n",
    "adam_epsilon = 1e-8\n",
    "warmup_steps = 0\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=warmup_steps, \n",
    "                                            num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a1bd17e9b643c687743e99fcca7ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1472 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.247789"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 1/2 [03:50<03:50, 230.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015899"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901dd3db45d84915a485cdee22908e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1472 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.265361"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 2/2 [07:38<00:00, 229.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011472"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange, notebook\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_iterator = trange(num_train_epochs, desc=\"Epoch\")\n",
    "\n",
    "## Put model in 'train' mode\n",
    "model.train()\n",
    "    \n",
    "for epoch in train_iterator:\n",
    "    epoch_iterator = notebook.tqdm(train_dataloader, desc=\"Iteration\")\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "\n",
    "        ## Reset all gradients at start of every iteration\n",
    "        model.zero_grad()\n",
    "        \n",
    "        ## Put the model and the input observations to GPU\n",
    "        model.to(device)\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        ## Identify the inputs to the model\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2]}\n",
    "\n",
    "        ## Forward Pass through the model. Input -> Model -> Output\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        ## Determine the deviation (loss)\n",
    "        loss = outputs[0]\n",
    "        print(\"\\r%f\" % loss, end='')\n",
    "\n",
    "        ## Back-propogate the loss (automatically calculates gradients)\n",
    "        loss.backward()\n",
    "\n",
    "        ## Prevent exploding gradients by limiting gradients to 1.0 \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        ## Update the parameters and learning rate\n",
    "        optimizer.step()\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93eb0fa5eb6649beb4f6f82394783fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/368 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Test data  0.949660152931181\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from torch.utils.data import SequentialSampler\n",
    "\n",
    "test_batch_size = 64\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, \n",
    "                             sampler=test_sampler, \n",
    "                             batch_size=test_batch_size)\n",
    "\n",
    "# Load the pre-trained model that was saved earlier \n",
    "# model = model.from_pretrained('/outputs')\n",
    "\n",
    "# Initialize the prediction and actual labels\n",
    "preds = None\n",
    "out_label_ids = None\n",
    "\n",
    "## Put model in \"eval\" mode\n",
    "model.eval()\n",
    "\n",
    "for batch in notebook.tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "    \n",
    "    ## Put the model and the input observations to GPU\n",
    "    model.to(device)\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    ## Do not track any gradients since in 'eval' mode\n",
    "    with torch.no_grad():\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2]}\n",
    "\n",
    "        ## Forward pass through the model\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        ## We get loss since we provided the labels\n",
    "        tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "        ## There maybe more than one batch of items in the test dataset\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, \n",
    "                                      inputs['labels'].detach().cpu().numpy(), \n",
    "                                      axis=0)\n",
    "    \n",
    "## Get final loss, predictions and accuracy\n",
    "preds = np.argmax(preds, axis=1)\n",
    "acc_score = accuracy_score(preds, out_label_ids)\n",
    "print ('Accuracy Score on Test data ', acc_score)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b9a973d92b2bc1dede9a05a941addeb708e25813980796a2bde874e36cb4963d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
